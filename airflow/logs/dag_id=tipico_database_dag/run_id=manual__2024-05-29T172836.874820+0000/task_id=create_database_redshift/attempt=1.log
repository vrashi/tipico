[2024-05-29T17:28:39.704+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: tipico_database_dag.create_database_redshift manual__2024-05-29T17:28:36.874820+00:00 [queued]>
[2024-05-29T17:28:39.719+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: tipico_database_dag.create_database_redshift manual__2024-05-29T17:28:36.874820+00:00 [queued]>
[2024-05-29T17:28:39.720+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2024-05-29T17:28:39.747+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): create_database_redshift> on 2024-05-29 17:28:36.874820+00:00
[2024-05-29T17:28:39.757+0000] {standard_task_runner.py:60} INFO - Started process 6097 to run task
[2024-05-29T17:28:39.762+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'tipico_database_dag', 'create_database_redshift', 'manual__2024-05-29T17:28:36.874820+00:00', '--job-id', '224', '--raw', '--subdir', 'DAGS_FOLDER/tipico_database_dag.py', '--cfg-path', '/tmp/tmp73mizh2r']
[2024-05-29T17:28:39.765+0000] {standard_task_runner.py:88} INFO - Job 224: Subtask create_database_redshift
[2024-05-29T17:28:39.823+0000] {task_command.py:423} INFO - Running <TaskInstance: tipico_database_dag.create_database_redshift manual__2024-05-29T17:28:36.874820+00:00 [running]> on host f167e9c2a292
[2024-05-29T17:28:39.922+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='tipico_database_dag' AIRFLOW_CTX_TASK_ID='create_database_redshift' AIRFLOW_CTX_EXECUTION_DATE='2024-05-29T17:28:36.874820+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-05-29T17:28:36.874820+00:00'
[2024-05-29T17:28:39.938+0000] {base.py:83} INFO - Using connection ID 'redshift_default' for task execution.
[2024-05-29T17:29:00.577+0000] {warnings.py:109} WARNING - /opt/***/dags/tipico_databse.py:43: UserWarning: DB-API extension cursor.connection used
  cursor.execute(sql)

[2024-05-29T17:29:00.581+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/redshift_connector/core.py", line 1793, in execute
    ps = cache["ps"][key]
KeyError: ('\n    CREATE TABLE EVENTS (\n    id int PRIMARY KEY,\n    startTime TIMESTAMPTZ,\n    messageTime TIMESTAMPTZ,\n    sportType varchar(255),\n    matchState varchar(255),\n    participants varchar(10000),\n    status varchar(255),\n    marketCount int,\n    group varchar(10000),\n    markets varchar(10000),\n    eventType varchar(255),\n    updatesCount int,\n    displayInfo varchar(255),\n    score varchar(10000),\n    gameClock varchar(10000),\n    eventReferences varchar(10000),\n    eventDetails varchar(10000),\n    sportCurrentGameState varchar(10000),\n    lastModifiedTime TIMESTAMPTZ,\n    eventTags varchar(10000),\n    created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP\n    );\n        ', ())

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/tipico_databse.py", line 43, in create_database_redshift
    cursor.execute(sql)
  File "/home/airflow/.local/lib/python3.8/site-packages/redshift_connector/cursor.py", line 248, in execute
    raise e
  File "/home/airflow/.local/lib/python3.8/site-packages/redshift_connector/cursor.py", line 241, in execute
    self._c.execute(self, operation, args)
  File "/home/airflow/.local/lib/python3.8/site-packages/redshift_connector/core.py", line 1874, in execute
    self.handle_messages(cursor)
  File "/home/airflow/.local/lib/python3.8/site-packages/redshift_connector/core.py", line 2166, in handle_messages
    raise self.error
redshift_connector.error.ProgrammingError: {'S': 'ERROR', 'C': '42601', 'M': 'syntax error at or near "group"', 'P': '248', 'F': '/home/ec2-user/padb/src/pg/src/backend/parser/parser_scan.l', 'L': '821', 'R': 'yyerror'}
[2024-05-29T17:29:00.603+0000] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=tipico_database_dag, task_id=create_database_redshift, execution_date=20240529T172836, start_date=20240529T172839, end_date=20240529T172900
[2024-05-29T17:29:00.639+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 224 for task create_database_redshift ({'S': 'ERROR', 'C': '42601', 'M': 'syntax error at or near "group"', 'P': '248', 'F': '/home/ec2-user/padb/src/pg/src/backend/parser/parser_scan.l', 'L': '821', 'R': 'yyerror'}; 6097)
[2024-05-29T17:29:00.670+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-05-29T17:29:00.697+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
